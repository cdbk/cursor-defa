#!/usr/bin/env python3
"""
Detailed Cursor User Rules Test Script
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ«ãƒ¼ãƒ«ã®è©³ç´°ãªæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class DetailedRulesTester:
    def __init__(self, rules_dir: str = "rules"):
        self.rules_dir = Path(rules_dir)
        
    def test_rule_structure(self) -> Dict:
        """ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ—ï¸ ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ãƒ†ã‚¹ãƒˆ...")
        
        results = {
            "passed": 0,
            "failed": 0,
            "issues": []
        }
        
        for mdc_file in self.rules_dir.rglob("*.mdc"):
            try:
                content = mdc_file.read_text(encoding='utf-8')
                issues = self._check_rule_structure(content, str(mdc_file))
                
                if not issues:
                    results["passed"] += 1
                else:
                    results["failed"] += 1
                    results["issues"].extend(issues)
                    
            except Exception as e:
                results["failed"] += 1
                results["issues"].append(f"{mdc_file}: æ§‹é€ ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ - {e}")
                
        return results
    
    def _check_rule_structure(self, content: str, filename: str) -> List[str]:
        """ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèª
        required_sections = [
            r'#\s*Cursor\s+Rules',
            r'##\s*\[',
            r'Copyright',
            r'MIT\s+License'
        ]
        
        for section in required_sections:
            if not re.search(section, content, re.IGNORECASE):
                issues.append(f"{filename}: å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹é€ ã®ç¢ºèª
        sections = re.findall(r'##\s*\[([^\]]+)\]', content)
        if not sections:
            issues.append(f"{filename}: ã‚»ã‚¯ã‚·ãƒ§ãƒ³å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ç¢ºèª
        code_blocks = re.findall(r'```[\w]*\n(.*?)\n```', content, re.DOTALL)
        if not code_blocks:
            issues.append(f"{filename}: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        return issues
    
    def test_rule_content_coverage(self) -> Dict:
        """ãƒ«ãƒ¼ãƒ«å†…å®¹ã®ç¶²ç¾…æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“š ãƒ«ãƒ¼ãƒ«å†…å®¹ã®ç¶²ç¾…æ€§ãƒ†ã‚¹ãƒˆ...")
        
        results = {
            "passed": 0,
            "failed": 0,
            "coverage_report": {}
        }
        
        # å„ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’åˆ†æ
        for mdc_file in self.rules_dir.rglob("*.mdc"):
            try:
                content = mdc_file.read_text(encoding='utf-8')
                coverage = self._analyze_content_coverage(content, str(mdc_file))
                results["coverage_report"][str(mdc_file)] = coverage
                
                if coverage["score"] >= 0.7:  # 70%ä»¥ä¸Šã®ã‚«ãƒãƒ¬ãƒƒã‚¸
                    results["passed"] += 1
                else:
                    results["failed"] += 1
                    
            except Exception as e:
                results["failed"] += 1
                results["coverage_report"][str(mdc_file)] = {"error": str(e)}
                
        return results
    
    def _analyze_content_coverage(self, content: str, filename: str) -> Dict:
        """ãƒ«ãƒ¼ãƒ«å†…å®¹ã®ç¶²ç¾…æ€§ã‚’åˆ†æ"""
        coverage = {
            "total_lines": len(content.split('\n')),
            "code_blocks": len(re.findall(r'```[\w]*\n(.*?)\n```', content, re.DOTALL)),
            "sections": len(re.findall(r'##\s*\[', content)),
            "examples": len(re.findall(r'ä¾‹|example|ã‚µãƒ³ãƒ—ãƒ«', content, re.IGNORECASE)),
            "keywords": len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', content)),
            "score": 0
        }
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = 0
        if coverage["total_lines"] > 50:
            score += 0.2
        if coverage["code_blocks"] > 0:
            score += 0.2
        if coverage["sections"] > 2:
            score += 0.2
        if coverage["examples"] > 0:
            score += 0.2
        if coverage["keywords"] > 100:
            score += 0.2
            
        coverage["score"] = score
        return coverage
    
    def test_rule_consistency(self) -> Dict:
        """ãƒ«ãƒ¼ãƒ«é–“ã®ä¸€è²«æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ”„ ãƒ«ãƒ¼ãƒ«é–“ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ...")
        
        results = {
            "passed": 0,
            "failed": 0,
            "inconsistencies": []
        }
        
        # å…¨ã¦ã®ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        rule_contents = {}
        for mdc_file in self.rules_dir.rglob("*.mdc"):
            try:
                content = mdc_file.read_text(encoding='utf-8')
                rule_contents[str(mdc_file)] = content
            except Exception as e:
                results["inconsistencies"].append(f"{mdc_file}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")
        
        # ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        inconsistencies = self._check_rule_consistency(rule_contents)
        results["inconsistencies"].extend(inconsistencies)
        
        if not inconsistencies:
            results["passed"] += 1
        else:
            results["failed"] += 1
            
        return results
    
    def _check_rule_consistency(self, rule_contents: Dict[str, str]) -> List[str]:
        """ãƒ«ãƒ¼ãƒ«é–“ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []
        
        # å…±é€šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        common_patterns = [
            r'Copyright.*2025.*Kentaro Kitagawa',
            r'MIT License',
            r'##\s*\[',
            r'```[\w]*\n'
        ]
        
        for pattern in common_patterns:
            files_with_pattern = []
            files_without_pattern = []
            
            for filename, content in rule_contents.items():
                if re.search(pattern, content, re.IGNORECASE):
                    files_with_pattern.append(filename)
                else:
                    files_without_pattern.append(filename)
            
            if files_without_pattern and files_with_pattern:
                inconsistencies.append(
                    f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã®ä¸€è²«æ€§ãŒã‚ã‚Šã¾ã›ã‚“: "
                    f"å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ« {len(files_with_pattern)}å€‹, "
                    f"å«ã¾ãªã„ãƒ•ã‚¡ã‚¤ãƒ« {len(files_without_pattern)}å€‹"
                )
        
        return inconsistencies
    
    def test_rule_effectiveness(self) -> Dict:
        """ãƒ«ãƒ¼ãƒ«ã®å®ŸåŠ¹æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ¯ ãƒ«ãƒ¼ãƒ«ã®å®ŸåŠ¹æ€§ãƒ†ã‚¹ãƒˆ...")
        
        results = {
            "passed": 0,
            "failed": 0,
            "effectiveness_scores": {}
        }
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§ãƒ«ãƒ¼ãƒ«ã®å®ŸåŠ¹æ€§ã‚’è©•ä¾¡
        test_scenarios = [
            {
                "name": "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™º",
                "question": "Reactã§ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•",
                "expected_rules": ["frontend_rules", "core_rules"]
            },
            {
                "name": "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º", 
                "question": "Node.jsã§APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®Ÿè£…ã™ã‚‹",
                "expected_rules": ["backend_rules", "core_rules"]
            },
            {
                "name": "ãƒ†ã‚¹ãƒˆå®Ÿè£…",
                "question": "Jestã§ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚’æ›¸ã",
                "expected_rules": ["testing_rules", "core_rules"]
            },
            {
                "name": "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°",
                "question": "ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
                "expected_rules": ["error_handling_rules", "core_rules"]
            }
        ]
        
        for scenario in test_scenarios:
            effectiveness = self._evaluate_rule_effectiveness(scenario)
            results["effectiveness_scores"][scenario["name"]] = effectiveness
            
            if effectiveness["score"] >= 0.8:
                results["passed"] += 1
            else:
                results["failed"] += 1
                
        return results
    
    def _evaluate_rule_effectiveness(self, scenario: Dict) -> Dict:
        """ãƒ«ãƒ¼ãƒ«ã®å®ŸåŠ¹æ€§ã‚’è©•ä¾¡"""
        question = scenario["question"]
        expected_rules = scenario["expected_rules"]
        
        # ç°¡æ˜“çš„ãªå®ŸåŠ¹æ€§è©•ä¾¡
        effectiveness = {
            "question": question,
            "expected_rules": expected_rules,
            "detected_rules": self._get_expected_rules(self._analyze_question_domain(question)),
            "score": 0
        }
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        if set(effectiveness["detected_rules"]) == set(expected_rules):
            effectiveness["score"] = 1.0
        elif any(rule in effectiveness["detected_rules"] for rule in expected_rules):
            effectiveness["score"] = 0.5
        else:
            effectiveness["score"] = 0.0
            
        return effectiveness
    
    def _analyze_question_domain(self, question: str) -> str:
        """è³ªå•ã‹ã‚‰æŠ€è¡“é ˜åŸŸã‚’åˆ¤å®š"""
        question_lower = question.lower()
        
        if any(keyword in question_lower for keyword in ["react", "vue", "angular", "ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ", "ui"]):
            return "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰"
        elif any(keyword in question_lower for keyword in ["node.js", "api", "ã‚µãƒ¼ãƒãƒ¼", "ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"]):
            return "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰"
        elif any(keyword in question_lower for keyword in ["jest", "ãƒ†ã‚¹ãƒˆ", "ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"]):
            return "ãƒ†ã‚¹ãƒˆ"
        elif any(keyword in question_lower for keyword in ["ã‚¨ãƒ©ãƒ¼", "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"]):
            return "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
        
        return "å…¨èˆ¬ãƒ»è¨­è¨ˆ"
    
    def _get_expected_rules(self, domain: str) -> List[str]:
        """æŠ€è¡“é ˜åŸŸã‹ã‚‰æœŸå¾…ã•ã‚Œã‚‹ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        rule_mapping = {
            "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰": ["frontend_rules", "core_rules"],
            "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰": ["backend_rules", "core_rules"],
            "ãƒ†ã‚¹ãƒˆ": ["testing_rules", "core_rules"],
            "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°": ["error_handling_rules", "core_rules"],
            "å…¨èˆ¬ãƒ»è¨­è¨ˆ": ["core_rules"]
        }
        return rule_mapping.get(domain, ["core_rules"])
    
    def run_detailed_tests(self) -> Dict:
        """è©³ç´°ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ğŸš€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ«ãƒ¼ãƒ«ã®è©³ç´°ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...\n")
        
        all_results = {
            "structure": self.test_rule_structure(),
            "coverage": self.test_rule_content_coverage(),
            "consistency": self.test_rule_consistency(),
            "effectiveness": self.test_rule_effectiveness()
        }
        
        # çµæœã‚µãƒãƒªãƒ¼
        total_passed = sum(result["passed"] for result in all_results.values())
        total_failed = sum(result["failed"] for result in all_results.values())
        
        print(f"\nğŸ“Š è©³ç´°ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"âœ… æˆåŠŸ: {total_passed}")
        print(f"âŒ å¤±æ•—: {total_failed}")
        if total_passed + total_failed > 0:
            print(f"ğŸ“ˆ æˆåŠŸç‡: {total_passed/(total_passed+total_failed)*100:.1f}%")
        
        return all_results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    tester = DetailedRulesTester()
    results = tester.run_detailed_tests()
    
    # è©³ç´°çµæœã®è¡¨ç¤º
    print("\nğŸ“‹ è©³ç´°ãƒ†ã‚¹ãƒˆçµæœ:")
    
    for test_name, result in results.items():
        print(f"\n{test_name.upper()}:")
        
        if "issues" in result and result["issues"]:
            print(f"  âŒ å•é¡Œç‚¹:")
            for issue in result["issues"][:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                print(f"    - {issue}")
            if len(result["issues"]) > 5:
                print(f"    ... ä»– {len(result['issues']) - 5} ä»¶")
        
        if "coverage_report" in result:
            print(f"  ğŸ“Š ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ:")
            for filename, coverage in list(result["coverage_report"].items())[:3]:
                if "error" not in coverage:
                    print(f"    {filename}: ã‚¹ã‚³ã‚¢ {coverage['score']:.2f}")
        
        if "effectiveness_scores" in result:
            print(f"  ğŸ¯ å®ŸåŠ¹æ€§ã‚¹ã‚³ã‚¢:")
            for scenario, score in result["effectiveness_scores"].items():
                print(f"    {scenario}: {score['score']:.2f}")

if __name__ == "__main__":
    main() 